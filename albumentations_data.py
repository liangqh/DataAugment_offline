#用来进行albumentations增强，主要解决了拷贝多个的问题import xml.dom.minidomimport cv2import randomimport albumentationsfrom albumentations import (    BboxParams, RandomGamma, Compose, Blur, CLAHE,    CenterCrop, HueSaturationValue, MotionBlur, Cutout,    VerticalFlip, HorizontalFlip, Flip, Transpose,    RandomCrop, RandomRotate90, ShiftScaleRotate,    GridDistortion, ElasticTransform, PadIfNeeded,    RGBShift, GaussianBlur, ChannelShuffle,    InvertImg, RandomFog, IAAAdditiveGaussianNoise,    IAAPiecewiseAffine, IAASharpen, IAAEmboss, OneOf,    MedianBlur, RandomBrightnessContrast, RandomSizedBBoxSafeCrop,    RandomRain, RandomShadow, RandomSnow, IAAAffine, Resize)import osimport globimport matplotlib.pyplot as pltimport pylabtry:    import xml.etree.cElementTree as ETexcept ImportError:    import xml.etree.ElementTree as ETimport sysdef read_xml(path):    exp_xml = []    dom = xml.dom.minidom.parse(path)    root = dom.documentElement    img_name = root.getElementsByTagName("filename")[0]    #exp_xml.append(img_name.childNodes[0].data + ".jpg")    exp_xml.append(img_name.childNodes[0].data)    label = root.getElementsByTagName("name")[0]    exp_xml.append(label.childNodes[0].data)    bonbox_xmin = root.getElementsByTagName("xmin")[0]    exp_xml.append(bonbox_xmin.childNodes[0].data)    bonbox_ymin = root.getElementsByTagName("ymin")[0]    exp_xml.append(bonbox_ymin.childNodes[0].data)    bonbox_xmax = root.getElementsByTagName("xmax")[0]    exp_xml.append(bonbox_xmax.childNodes[0].data)    bonbox_ymax = root.getElementsByTagName("ymax")[0]    exp_xml.append(bonbox_ymax.childNodes[0].data)    return exp_xmldef modify_xml(path, bbox, new_img_name, aug_file, num, n, shape0, shape1):    new_dom = xml.dom.minidom.parse(path)    new_root = new_dom.documentElement    new_img_name = new_img_name + '.jpg'    new_img_xml_name = new_root.getElementsByTagName("filename")[0]    new_img_xml_name.childNodes[0].data = new_img_name    new_bonbox_xmin = new_root.getElementsByTagName("xmin")[0]    new_bonbox_xmin.childNodes[0].data = bbox[0]    new_bonbox_ymin = new_root.getElementsByTagName("ymin")[0]    new_bonbox_ymin.childNodes[0].data = bbox[1]    new_bonbox_xmax = new_root.getElementsByTagName("xmax")[0]    new_bonbox_xmax.childNodes[0].data = bbox[2]    new_bonbox_ymax = new_root.getElementsByTagName("ymax")[0]    new_bonbox_ymax.childNodes[0].data = bbox[3]    new_shape0 = new_root.getElementsByTagName("height")[0]    new_shape0.childNodes[0].data = shape0    new_shape1 = new_root.getElementsByTagName("width")[0]    new_shape1.childNodes[0].data = shape1    with open(os.path.join(aug_file,        aug_file + "\\aug_img{}_{}.xml".format(n, num)), 'w') as fh:        new_dom.writexml(fh)def read_xml_annotations(path):    name_xml = []    objecttype_list = []    bndboxlist = []    tree = ET.parse(path)    root1 = tree.getroot()    #print("root:", root1.findall('filename')[0].text)    filename = root1.findall('filename')[0].text    #name_xml.append(filename)    for object in root1.findall('object'):        #找到root节点下所有object节点        object_type = object.find('name').text        '''        if object_type == 'car' or  object_type == 'truck' or object_type == 'big_fork_truck' or object_type == 'small_fork_truck' or object_type == 'pick_up_truck':            object_type = 0        elif object_type == 'person':            #print("person_here")            object_type = 1        '''        if object_type == 'bird_nest':            object_type = 0        objecttype_list.append(object_type)        bndbox = object.find('bndbox')        xmin = int(bndbox.find('xmin').text)        xmax = int(bndbox.find('xmax').text)        ymin = int(bndbox.find('ymin').text)        ymax = int(bndbox.find('ymax').text)        bndboxlist.append([xmin, ymin, xmax, ymax])    #bndbox = root1.find('obhect').find('bndbox')    return filename, objecttype_list, bndboxlistdef modify_xml_annotations(path, bbox, new_img_name, aug_file, num, n, shape0, shape1):    tree = ET.parse(path)    root1 = tree.getroot()    index = 0    exchange = new_img_name    new_img_name = new_img_name + '.jpg'    new_img_xml_name = root1.findall('filename')[0]    new_img_xml_name.text = new_img_name    print("new_img_xml_name:", new_img_xml_name.text)    root1.findall('filename')[0].text = new_img_name    bbox_list_len = len(bbox)    for object in root1.findall('object'):#找到root节点下的所有bndbox节点        if index < bbox_list_len:            bndbox = object.find('bndbox')            new_xmin = bndbox.find('xmin')            new_xmin.text = str(bbox[index][0])            new_ymin = bndbox.find('ymin')            new_ymin.text = str(bbox[index][1])            new_xmax = bndbox.find('xmax')            new_xmax.text = str(bbox[index][2])            new_ymax = bndbox.find('ymax')            new_ymax.text = str(bbox[index][3])        else:            root1.remove(object)        index = index + 1    #with open(os.path.join(aug_file, "//ro_aug_time{}_{}.xml".format(n, exchange)), 'w') as fh:        #tree.write(fh)    new_shape0 = root1.findall('size')[0].find('height')    new_shape0.text = str(shape0)    new_shape1 = root1.findall('size')[0].find('width')    new_shape1.text = str(shape1)    tree.write(os.path.join(aug_file, "{}.xml".format(exchange)))#for vocdef visualize_bbox(img, bbox, class_id, class_idx_to_name):    bbox = list(bbox)    x_min, y_min, x_max, y_max = bbox    x_min = int(x_min)    x_max = int(x_max)    y_min = int(y_min)    y_max = int(y_max)    image = cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)    class_name = class_idx_to_name[class_id]    ((text_width, text_height), _) = cv2.getTextSize(class_name,                                                     cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    cv2.rectangle(image, (x_min, y_min - int(1.3 * text_height)),                  (x_min + text_width, y_min), (255, 0, 0), -1)    cv2.putText(image, class_name, (x_min, y_min - int(0.3 * text_height)),                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 255), lineType=cv2.LINE_AA)    return imagedef visualize_bbox_coco(img, bbox, class_id, class_idx_to_name):    bbox = list(bbox)    x_min, y_min, w, h = bbox    x_min = int(x_min)    x_max = int(x_min + w)    y_min = int(y_min)    y_max = int(y_min + h)    image = cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)    class_name = class_idx_to_name[class_id]    ((text_width, text_height), _) = cv2.getTextSize(class_name,                                                     cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    cv2.rectangle(image, (x_min, y_min - int(1.3 * text_height)),                  (x_min + text_width, y_min), (255, 0, 0), -1)    cv2.putText(image, class_name, (x_min, y_min - int(0.3 * text_height)),                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 255), lineType=cv2.LINE_AA)    return image#这个函数没有用到def get_aug(aug, min_area=0., min_visibility=0.):    return Compose(aug, bbox_params=BboxParams(format='pascal_voc',                                               min_area=min_area,                                               min_visibility=min_visibility,                                               label_fields=["category_id"]))#用的是这个函数'''Albumentation库还支持boxes裁剪和删除主要包括两个参数：min_area和min_visibility默认这两个参数都是0，只有超出图片尺度之外的boxes才会被删除如果目标面积小于min_area就不进行标注如果目标可见性小于threshold：变换后，dog的box面积大约是原始box的25%，小于0.3，故舍弃.'''def augment():    aug = Compose([        #Resize(p=1, height=5000, width=5000)],        #Blur(blur_limit=7, p=0.3),#使用随机大小的内核模糊输入图像        #RandomGamma(gamma_limit=(80, 120), p=0.2),        #CenterCrop(height=360, width=640, p=1)],        #VerticalFlip(p=0.2),#围绕X轴垂直翻转输入        #HorizontalFlip(p=1),#围绕Y轴水平翻转输入        #Flip(p=1),#垂直或者水平和垂直翻转输入        #Transpose(p=1),#通过交换行和列来转置输入        #RandomCrop(height=300, width=500, p=1)],#剪裁输入的随机部分        #RandomSizedBBoxSafeCrop(height=614, width=614, p=1)],#剪裁输入的随机部分        #RandomRotate90(p=1),#将输入随机旋转90度,零次或多次        #ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=60, interpolation=1,                         #border_mode=4, value=None, mask_value=None, p=1)],        #随机应用放射变换：平移、缩放和旋转输入        #HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30,                           #val_shift_limit=20, p=1),#随机更改输入图像的色相，饱和度和值        PadIfNeeded(min_height=3000, min_width=3000, border_mode=1, value=None,                    mask_value=None, always_apply=False, p=1)],#多加很多个，但是多加的没有框，有bug        #RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20, p=1),#为输入RGB图像的每个通道随机移动数值        #GaussianBlur(blur_limit=7, always_apply=False, p=0.2),#使用具有随机核大小的高斯滤波器        #CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1),#将对比度受限的自适应直方图均衡应用于输入图像        #ChannelShuffle(p=1)[source]],#随机重新排列输入RGB图像的通道，不能用        #InvertImg(p=1),#通过从255减去像素值来反转输入图像        #Cutout(num_holes=8, max_h_size=8, max_w_size=8, fill_value=0, p=0.2),#随机擦除        #RandomFog(fog_coef_lower=0.2, fog_coef_upper=0.2, alpha_coef=0.5, p=0.6),#模拟图像雾        #RandomRain(slant_lower=-5, slant_upper=5, drop_length=10, drop_width=1, drop_color=(200, 200, 200),                   #blur_value=3, brightness_coefficient=0.4, rain_type=None, always_apply=False, p=0.8),        #RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=3, shadow_dimension=3, always_apply=False, p=0.8),        #RandomSnow(snow_point_lower=0.1, snow_point_upper=0.3, brightness_coeff=2.5, always_apply=False, p=0.2)],        ##IAAAdditiveGaussianNoise(p=0.2)],        #IAAPiecewiseAffine, IAASharpen, IAAEmboss        #IAAPiecewiseAffine(scale=(0.01, 0.03), nb_rows=5, nb_cols=5,                           #order=1, cval=0, mode='constant', always_apply=False, p=1)],        #IAAAffine(p=1, scale=1.0, translate_percent=0.6)],        #IAASharpen(p=1)],        #IAAEmboss(p=1)],        bbox_params=BboxParams(format='pascal_voc',                               min_area=20.,                               min_visibility=0.3,                               label_fields=["category_id"])        )    aug2 = Compose([        #RandomRotate90(),        #Flip(),        #Transpose(),        IAAAdditiveGaussianNoise(p=0.1),        OneOf([            MotionBlur(p=0.2),            MedianBlur(blur_limit=3, p=0.1),            Blur(blur_limit=3, p=0.1),        ], p=0.2),        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=30, interpolation=1,                         border_mode=4, value=None, mask_value=None, p=0.5),        OneOf([            CLAHE(clip_limit=2),            IAASharpen(),            IAAEmboss(),            RandomBrightnessContrast(),        ], p=0.2)],        bbox_params = BboxParams(format='pascal_voc',                                min_area=20.,                                min_visibility=0.3,                                label_fields=["category_id"])    )    return aug2def get_data(xml_data_path, img_path):    xml_data = read_xml(xml_data_path)    print("lujing:", img_path+'//'+xml_data[0])    img = cv2.imread(img_path + '//' + xml_data[0])    bbox = [[int(xml_data[2]), int(xml_data[3]), int(xml_data[4]), int(xml_data[5])]]    return bbox, imgdef get_data_mine(xml_data_path, img_path):    filename, objecttype_list, bndboxlist = read_xml_annotations(xml_data_path)    print("lujing:", img_path + '//' + filename)    img = cv2.imread(img_path + '//' + filename)    return objecttype_list, bndboxlist, img, filenamedef keep_aug_img(annotations):    aug_img = annotations['image'].copy()    #if annotations['bboxes'] == None:       # print("here")    if len(annotations['bboxes']) == 2:        print("wei0__________________________________________")    if len(annotations['bboxes']) > 0:        for idx, bbox in enumerate(annotations['bboxes']):            bbox = list(bbox)            x_min, y_min, x_max, y_max = bbox            x_min = int(x_min)            y_min = int(y_min)            x_max = int(x_max)            y_max = int(y_max)            aug_bbox = [x_min, y_min, x_max, y_max]            return aug_img, aug_bbox    else:        return None, Nonedef keep_aug_img_mine(annotations):    aug_img = annotations['image'].copy()    aug_bbox_list = []    if len(annotations['bboxes']) > 0:        for idx, bbox in enumerate(annotations['bboxes']):            bbox = list(bbox)            x_min, y_min, x_max, y_max = bbox            x_min = int(x_min)            y_min = int(y_min)            x_max = int(x_max)            y_max = int(y_max)            aug_bbox = [x_min, y_min, x_max, y_max]            aug_bbox_list.append(aug_bbox)        return aug_img, aug_bbox_list    else:        return None, Nonedef visualize(annotations, category_id_to_name):    img = annotations['image'].copy()    for idx, bbox in enumerate(annotations['bboxes']):        img = visualize_bbox(img, bbox, annotations['category_id'][idx], category_id_to_name)        #return img    plt.figure(figsize=(12, 12))    plt.imshow(img)    pylab.show()def main():    #xml_img_path = r"C:\Users\27319\Documents\GitHub\yolov3-master\data"    xml_path = r"/media/cjh/code/data/train/label_aug_pad+yuan"    img_path = r"/media/cjh/code/data/train/img_aug_pad+yuan"    #存放xml和img的数据地址    aug_file = r"/media/cjh/code/data/train/data_rotate_1"    #增强的数据地址    shample = 2 #需要增强的次数    for n in range(shample):        num = 0        print("第%d次" % n)        for xml_name in glob.glob(xml_path + "/*.xml"):            print("第%d张图片" % num)            print("xml_name:", xml_name)            objecttype, bndbox, img, filename = get_data_mine(xml_name, img_path)            print("object_type:", objecttype)            print("bndbox:", bndbox)            annotations = {'image': img, 'bboxes': bndbox, 'category_id': objecttype}            #category_id_to_name = {0: 'car', 1: 'person'}#现在只对鸟巢作处理            category_id_to_name = {0: 'bird_nest'}            aug = augment()            augmented = aug(**annotations)            #visualize(augmented, category_id_to_name)            aug_img, aug_bbox = keep_aug_img_mine(augmented)            if aug_bbox != None:                print("aug_bbox:", aug_bbox)                print("size:", aug_img.shape[0])  # shape[0]是高,shape[1]是宽                shape_0 = aug_img.shape[0]                shape_1 = aug_img.shape[1]                #cv2.imwrite(aug_file + "/aug_time{}_{}.jpg".format(n, filename), aug_img)                cv2.imwrite(aug_file + "/ro_aug_time{}_{}".format(n, filename), aug_img)                new_xml_path = os.path.split(aug_file + "/ro_aug_time{}_{}.jpg".format(n, filename))[1]                new_xml_name = new_xml_path.split(".")[0]  # 获取xml名字                print("new_xml_name:", new_xml_name)                modify_xml_annotations(xml_name, aug_bbox, new_xml_name, aug_file, num, n, shape_0, shape_1)            '''            if num == 6:                visualize(augmented, category_id_to_name)                aug_img, aug_bbox = keep_aug_img_mine(augmented)                if aug_bbox != None:                    print("aug_bbox:", aug_bbox)                    print("size:", aug_img.shape[0])  # shape[0]是高,shape[1]是宽                    shape_0 = aug_img.shape[0]                    shape_1 = aug_img.shape[1]                    cv2.imwrite(aug_file + "/aug_time{}_{}.jpg".format(n, filename), aug_img)                    new_xml_path = os.path.split(aug_file + "/aug_time{}_{}.jpg".format(n, filename))[1]                    new_xml_name = new_xml_path.split(".")[0]  # 获取xml名字                    print("new_xml_name:", new_xml_name)                    modify_xml_annotations(xml_name, aug_bbox, new_xml_name, aug_file, num, n, shape_0, shape_1)            '''            num += 1if __name__ == "__main__":    main()